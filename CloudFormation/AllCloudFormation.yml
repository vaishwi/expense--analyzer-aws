AWSTemplateFormatVersion: 2010-09-09
# Configuration parameters which will be used while creating resources
Parameters:
  IAMLabRole:
    Type: String
    Default: "arn:aws:iam::238138732282:role/LabRole"
  S3Bucketname:
    Type: String
    Default: expense-project-bucket
  DynamoTableName:
    Type: String
    Default: 'receipt-extraction-data'
  CognitoServicePrefix:
    Type: String
    Default: 'expense-analyzer'
  APIName:
    Type: String
    Default: expense
  EnvironmentName:
    Type: String
    Default: Prod
  TableName:
    Type: String
    Default: receipt-extraction-data
  FetchHistoryLambdaFunctionName:
    Type: String
    Default: fetch_history
  APIFetchHistoryPathPart:
    Type: String
    Default: fetchhistory

  ReceiptAnalyzerLambdaFunctionName:
    Type: String
    Default: receipt_analyzer
  APIReceiptAnalyzerPathPart:
    Type: String
    Default: analyzereceipt

  S3UplaodLambdaFunctionName:
    Type: String
    Default: s3_uplaod
  APIS3UploadPathPart:
    Type: String
    Default: uploadimage

  InstanceTypeParameter:
    Description: Select instance type 
    Type: String
    Default: t2.small
    AllowedValues: 
        - t2.micro
        - m1.small
        - m1.large
        - t2.small
    Description: Enter t2.micro, m1.small or m1.large. Default is t2.micro.

  KeyName:
    Default: vaishwiA2
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance
    Type: AWS::EC2::KeyPair::KeyName
  
  GitcodeLink:
    Default: "https://github.com/vaishwi/expense-analyzer"
    Type: String


Resources:
  # S3
  S3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref S3Bucketname

  S3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      PolicyDocument:
        Statement:
          - Effect: Allow
            Principal: "*"
            Action:
              - s3:GetObject
              - s3:PutObject
            Resource: !Sub 'arn:aws:s3:::${S3Bucket}/*'
      Bucket: !Ref S3Bucket
  # Dynamo DB  
  DDBTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Ref DynamoTableName
      AttributeDefinitions:
        -
          AttributeName: "analyzeId"
          AttributeType: "S"
        -
          AttributeName: "userEmail"
          AttributeType: "S"
      KeySchema:
        -
          AttributeName: "analyzeId"
          KeyType: "HASH"
        -
          AttributeName: "userEmail"
          KeyType: "RANGE"
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5
  # Cognito Userpool  
  UserPool:
    Type: 'AWS::Cognito::UserPool'
    Properties:
      UsernameConfiguration:
        CaseSensitive: true
      AutoVerifiedAttributes:
        - email
      UserPoolName: !Sub ${CognitoServicePrefix}-UserPool
      UsernameAttributes: 
        - email
      Schema:
        - Name: email
          AttributeDataType: String
          Mutable: true
          Required: true
      VerificationMessageTemplate:
        DefaultEmailOption: CONFIRM_WITH_LINK
        EmailMessageByLink: 'Please click the link below to verify your email address. {##Verify Email##}'
      Policies:
        PasswordPolicy:
          RequireLowercase: true
          RequireSymbols: false
          RequireNumbers: true
          MinimumLength: 6
          RequireUppercase: false

  UserPoolClient:
    Type: AWS::Cognito::UserPoolClient
    Properties:
      AccessTokenValidity: 1
      TokenValidityUnits: days
      UserPoolId: !Ref UserPool
      TokenValidityUnits:
        AccessToken: days
      SupportedIdentityProviders:
        - COGNITO

  UserPoolDomain:
    Type: AWS::Cognito::UserPoolDomain
    Properties:
      Domain: !Ref CognitoServicePrefix
      UserPoolId: !Ref UserPool
  # Api gateway for rest api
  APIGateWayRestApi:
    Type: "AWS::ApiGateway::RestApi"
    Properties:
      Name: !Ref APIName
  
  Cognitoauthorizer:
    Type: AWS::ApiGateway::Authorizer
    Properties:
      IdentitySource: method.request.header.authorization
      Name: CognitoAuthorizer
      ProviderARNs:
        - Fn::GetAtt:
            - UserPool
            - Arn
      RestApiId: !Ref APIGateWayRestApi
      Type: COGNITO_USER_POOLS

  APIGatewayFetchHistoryResource:
    Type: "AWS::ApiGateway::Resource"
    Properties:
      RestApiId: !Ref APIGateWayRestApi
      ParentId: !GetAtt
        - APIGateWayRestApi
        - RootResourceId
      PathPart:
        Ref: APIFetchHistoryPathPart
    DependsOn:
      - APIGateWayRestApi

  APIGatewayFetchHistoryMethod:
    Type: "AWS::ApiGateway::Method"
    Properties:
      RestApiId: !Ref APIGateWayRestApi
      ResourceId: !Ref APIGatewayFetchHistoryResource
      HttpMethod: POST
      AuthorizationType: COGNITO_USER_POOLS
      AuthorizerId: !Ref Cognitoauthorizer
      MethodResponses:
        - StatusCode: 200
      Integration:
        Type: AWS
        IntegrationResponses:
          - StatusCode: 200
        IntegrationHttpMethod: POST
        Uri: !Sub
          - >-
            arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${LambdaFuncNameArn}/invocations
          - LambdaFuncNameArn: !GetAtt FetchHistoryLambdaFunction.Arn
    DependsOn:
      - APIGatewayFetchHistoryResource


  # Lambda Function for fetching the history
  FetchHistoryLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Runtime: "python3.9"
      Role: !Ref IAMLabRole
      Code:
        ZipFile: |
          import json
          import base64
          import boto3
          import os

          dyn_client = boto3.client('dynamodb')

          # TABLE_NAME = "receipt_extraction_data"
          # BUCKET_NAME = "expense-project"
          TABLE_NAME = os.environ['TABLE_NAME']
          BUCKET_NAME =os.environ['BUCKET_NAME']

          def convert_dynamoStrDict_to_dict(dynamoDict):
            responseDict = {}
            
            for key in dynamoDict.keys():
                responseDict[key] = dynamoDict[key]['S']
            return responseDict

          def get_base64_image_data_from_s3(fileName):
              s3 = boto3.resource('s3')
              bucket = s3.Bucket(BUCKET_NAME)
              obj = bucket.Object(key = fileName)      #pass your image Name to key
              response = obj.get()     #get Response
              img = response[u'Body'].read()        # Read the respone, you can also print it.
              #print(type(img))                      # Just getting type.
              myObj = [base64.b64encode(img)] 
              print(myObj)
              return myObj

          def convert_dynamoData_str(history_records):
              output_records = []
              for record in history_records:
                items = record['Items']['L']
                newItems = []  
                for item in items:
                  item = item['M']
                  newItems.append(convert_dynamoStrDict_to_dict(item))
              
                record.pop('Items')
                print(record)
                responseDict = convert_dynamoStrDict_to_dict(record)
                responseDict['items'] = newItems
                print(responseDict)
                responseDict['image'] = get_base64_image_data_from_s3(responseDict['fileName'])
                responseDict['fileName'] = responseDict['fileName'].split("/")[1]
                print(responseDict)
                output_records.append(responseDict)
              return output_records



          def getHistoryFromDatabase(userEmail):
              
              history = dyn_client.scan(TableName=TABLE_NAME, FilterExpression='userEmail = :userEmail',
                                      ExpressionAttributeValues={
                                          ':userEmail': {'S': userEmail}
                                      })

              return history

          def lambda_handler(event, context):
              # TODO implement
              userEmail = event["userEmail"]
              history = getHistoryFromDatabase(userEmail)
              print(history)
              
              if(history['Count']==0):
                  response = []
              else:
                  history_records = history['Items']
                  response = convert_dynamoData_str(history_records)
              
              return {
                  'statusCode': 200,
                  'history': response
              }

      FunctionName:
        Ref: FetchHistoryLambdaFunctionName
      Handler: index.lambda_handler
      
      Timeout: 300
      Description: Invoke a function during stack creation.
      Environment:
        Variables:
          BUCKET_NAME: !Ref S3Bucketname
          TABLE_NAME: !Ref TableName
      TracingConfig:
        Mode: Active
    DependsOn:
      - APIGateWayRestApi

  APIGatewayReceiptAnalyzerResource:
    Type: "AWS::ApiGateway::Resource"
    Properties:
      RestApiId: !Ref APIGateWayRestApi
      ParentId: !GetAtt
        - APIGateWayRestApi
        - RootResourceId
      PathPart:
        Ref: APIReceiptAnalyzerPathPart
    DependsOn:
      - APIGateWayRestApi

  APIGatewayReceiptAnalyzerMethod:
    Type: "AWS::ApiGateway::Method"
    Properties:
      RestApiId: !Ref APIGateWayRestApi
      ResourceId: !Ref APIGatewayReceiptAnalyzerResource
      HttpMethod: POST
      AuthorizationType: COGNITO_USER_POOLS
      AuthorizerId: !Ref Cognitoauthorizer
      MethodResponses:
        - StatusCode: 200
      Integration:
        Type: AWS
        IntegrationResponses:
          - StatusCode: 200
        IntegrationHttpMethod: POST
        Uri: !Sub
          - >-
            arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${LambdaFuncNameArn}/invocations
          - LambdaFuncNameArn: !GetAtt ReceiptAnalyzerLambdaFunction.Arn
    DependsOn:
      - APIGatewayReceiptAnalyzerResource
      
  # Lambda Function for extracting and anlyzing receipt
  ReceiptAnalyzerLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Runtime: "python3.9"
      Role: !Ref IAMLabRole
      Code:
        ZipFile: |
          import boto3
          import io
          from urllib.parse import unquote_plus
          import json
          import uuid
          import base64
          import os

          dyn_client = boto3.client('dynamodb')
          # TABLE_NAME = "receipt_extraction_data"
          TABLE_NAME = os.environ['TABLE_NAME']
          BUCKET_NAME =os.environ['BUCKET_NAME']
          # Takes a field as an argument and prints out the detected labels and values
          def print_labels_and_values(field):
              # Only if labels are detected and returned
              value  = field['ValueDetection']['Text']
              value = value.replace("\n"," ")
              print(field['Type']['Text']+" - "+value)

          def get_summary_fields(summary_fields, keys):
              outputDict = {}
              for key in keys:
                  outputDict[key] = ""
              for summary_field in summary_fields:
                  
                  # print_labels_and_values(summary_field)
                  value  = summary_field['ValueDetection']['Text']
                  value = value.replace("\n"," ")
                  key = summary_field['Type']['Text'].upper()
                  result = keys.count(key)
                  if key in keys:
                      outputDict[key] = value
                  print()
              return outputDict
              
              
          def get_purchase_items(line_item_groups):
              items = []
              distinctItemKeys = []
              for line_item_group in line_item_groups:
                  tempItem = {}
                  
                  for line_items in line_item_group["LineItems"]:
                      
                      print(line_items)
                      for expense_fields in line_items["LineItemExpenseFields"]:
                          
                          value  = expense_fields['ValueDetection']['Text']
                          value = value.replace("\n"," ")
                          key = expense_fields['Type']['Text'].upper()
                          if ( (key != "EXPENSE_ROW") & (len(distinctItemKeys)==0)):
                              distinctItemKeys.append(key)
                          if(key=="EXPENSE_ROW"):
                              print("In expense row")
                              continue
                          if(key in distinctItemKeys):
                              items.append(tempItem)
                              tempItem={}
                          else:
                              tempItem[key]=value
                              
              return items
              
          def convert_string_attr_dynamo_attr(input_dict):
              dynamoData = {}
              for key in input_dict:
                  print(key)
                  dynamoData[key] = {'S': input_dict[key]}
              return dynamoData

          def convert_list_attr_dynamo_map(input_list_dict_ele):
              dynamoItems = []
              for item in input_list_dict_ele:
                  print(item)
                  dynamoItem = convert_string_attr_dynamo_attr(item)
                  dynamoItems.append({'M':dynamoItem})
              
              dynamoItems = {'L': dynamoItems}
              return dynamoItems
              

          def process_expense_analysis(bucket,file_name,client):
              print("In side analysis")
              
              
            
              print(file_name)
              
              # Analyze document
              # process using S3 object
              response = client.analyze_expense(
                  Document={'S3Object': {'Bucket': bucket, 'Name': file_name}})
              
              return response["ExpenseDocuments"]

          def lambda_handler(event,context):
              
              print("Hureeeee in lambda")
              client = boto3.client('textract')

              
              # bucket = event['bucket']
              userEmail = event['userEmail']
              file_name =userEmail+"/"+ event['file_name']
              
              s3_client = boto3.client('s3')
              
              response = process_expense_analysis(BUCKET_NAME,file_name,client)
              
              # print(response)
              outputDict = {}
              outputDict["ITEMS"] =[]
              
              keys = ["ADDRESS","STREET","CITY","STATE","ZIP_CODE","NAME","VENDER_PHONE","DATE","TOTAL","DISCOUNT","TAX"]

              # response = event 
              response = response[0]
              summary_fields = response["SummaryFields"]
              line_items_groups = response["LineItemGroups"]
              outputDict = get_summary_fields(summary_fields, keys)

              print("Line Item Groups")
              items=get_purchase_items(line_items_groups)
              
              dynamoData = convert_string_attr_dynamo_attr(outputDict)
              
              dynamoData["analyzeId"]= {'S': str(uuid.uuid4())}
              dynamoData["userEmail"]= {'S': userEmail}
              dynamoData["fileName"]= {'S': file_name}

              dynamoData['Items'] = convert_list_attr_dynamo_map(items[1:])
            

              response = dyn_client.put_item(TableName=TABLE_NAME, Item=dynamoData)
              outputDict['items'] = items[1:]
              
              return outputDict

      FunctionName:
        Ref: ReceiptAnalyzerLambdaFunctionName
      Handler: index.lambda_handler
      Timeout: 300
      Description: Function to extract and analyze receipt.
      Environment:
        Variables:
          BUCKET_NAME: !Ref S3Bucketname
          TABLE_NAME: !Ref TableName
      TracingConfig:
        Mode: Active
    DependsOn:
      - APIGateWayRestApi

  APIGatewayS3UploadResource:
    Type: "AWS::ApiGateway::Resource"
    Properties:
      RestApiId: !Ref APIGateWayRestApi
      ParentId: !GetAtt
        - APIGateWayRestApi
        - RootResourceId
      PathPart:
        Ref: APIS3UploadPathPart
    DependsOn:
      - APIGateWayRestApi

  APIGatewayS3UploadMethod:
    Type: "AWS::ApiGateway::Method"
    Properties:
      RestApiId: !Ref APIGateWayRestApi
      ResourceId: !Ref APIGatewayS3UploadResource
      HttpMethod: POST
      AuthorizationType: COGNITO_USER_POOLS
      AuthorizerId: !Ref Cognitoauthorizer
      MethodResponses:
        - StatusCode: 200
      Integration:
        Type: AWS
        IntegrationResponses:
          - StatusCode: 200
        IntegrationHttpMethod: POST
        Uri: !Sub
          - >-
            arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${LambdaFuncNameArn}/invocations
          - LambdaFuncNameArn: !GetAtt S3UploadLambdaFunction.Arn
    DependsOn:
      - APIGatewayS3UploadResource

  # Lambda Function for uploading image to s3
  S3UploadLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Runtime: "python3.9"
      Role: !Ref IAMLabRole
      Code:
        ZipFile: |
          import json
          import boto3
          import base64
          import os

          BUCKET_NAME =os.environ['BUCKET_NAME']
          def lambda_handler(event, context):
              print(event)
              encoded_data = event['imageData']
              # bucket = event['bucket']
              userEmail = event['userEmail']
              file_name = event['file_name']
              
              if("data" in encoded_data):
                  encoded_data = encoded_data.split(",")[1]

              
              #decode base64 string data
              decoded_data=base64.b64decode((encoded_data))
              
              file_name = userEmail+"/"+file_name
              
              
              s3 = boto3.resource('s3')
              obj = s3.Object(BUCKET_NAME,file_name)
              obj.put(Body=base64.b64decode(encoded_data))
              
              # TODO implement
              return {
                  'statusCode': 200,
                  'body': json.dumps('Successfully stored.')
              }

      FunctionName:
        Ref: S3UplaodLambdaFunctionName
      Handler: index.lambda_handler
      
      Timeout: 300
      Description: Function to uplaod image to s3 bucket.
      Environment:
        Variables:
          BUCKET_NAME: !Ref S3Bucketname
      TracingConfig:
        Mode: Active
    DependsOn:
      - APIGateWayRestApi
  
  APIGatewayDeployment:
    Type: "AWS::ApiGateway::Deployment"
    Properties:
      RestApiId: !Ref APIGateWayRestApi
      StageName:
        Ref: EnvironmentName
    DependsOn:
      - APIGatewayFetchHistoryMethod
      - APIGatewayS3UploadMethod
      - APIGatewayReceiptAnalyzerMethod
  
  APIGatewayFetchHistoryPermission:
    Type: "AWS::Lambda::Permission"
    Properties:
      Action: "lambda:InvokeFunction"
      FunctionName: !GetAtt FetchHistoryLambdaFunction.Arn
      Principal: apigateway.amazonaws.com
    DependsOn:
      - APIGatewayDeployment

  APIGatewayReceiptAnalyzePermission:
    Type: "AWS::Lambda::Permission"
    Properties:
      Action: "lambda:InvokeFunction"
      FunctionName: !GetAtt ReceiptAnalyzerLambdaFunction.Arn
      Principal: apigateway.amazonaws.com
    DependsOn:
      - APIGatewayDeployment

  APIGatewayS3UploadPermission:
    Type: "AWS::Lambda::Permission"
    Properties:
      Action: "lambda:InvokeFunction"
      FunctionName: !GetAtt S3UploadLambdaFunction.Arn
      Principal: apigateway.amazonaws.com
    DependsOn:
      - APIGatewayDeployment


    # Security group
  InstanceSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties: 
      GroupDescription: Enable SSH and internet access.
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 3000
          ToPort: 3000
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0

  # Ec2 Instance
  Ec2Instance: 
    Type: AWS::EC2::Instance # Type
    Properties:
      InstanceType: !Ref InstanceTypeParameter
      ImageId: ami-06e46074ae430fba6
      KeyName: !Ref 'KeyName'
      SecurityGroups: 
        - !Ref InstanceSecurityGroup

      # Executing Commands when EC2 instance 
      UserData:
        Fn::Base64:
          !Sub |
            #!/bin/bash
            sudo su
            yum install git -y
            git clone ${GitcodeLink}
            cd expense-analyzer/
            pwd
            rm .env

            echo "REACT_APP_API_LINK=\"https://${APIGateWayRestApi}.execute-api.${AWS::Region}.amazonaws.com/${EnvironmentName}/\"" > .env
            echo "REACT_APP_CLIENT_ID=${UserPoolClient}" >> .env
            echo "REACT_APP_USERPOOL_ID=${UserPool}" >> .env
            echo "REACT_APP_S3_UPLOAD_PATH=${APIS3UploadPathPart}" >> .env
            echo "REACT_APP_RECEIPT_ANALYZE_PATH=${APIReceiptAnalyzerPathPart}" >> .env
            echo "REACT_APP_FETCH_HISTORY_PATH=${APIFetchHistoryPathPart}" >> .env
            yum install nodejs -y
            yum install npm -y
            echo "Vaishwi- install node and npm"
            npm install --force
            echo "Vaishwi-  npm install complete"
            npm run start&
            echo "Vaishwi-  npm start complete"
      Tags:
        - Key: Name
          Value: Expense-analyzer-ec2
      

  
# Outputs of front end and back end services URLs
Outputs:
  CognitoUserPoolID:
    Value: !Ref UserPool
    Description: The UserPool ID
  CognitoAppClientID:
    Value: !Ref UserPoolClient
    Description: The app client
  ProdAPIEndpoint:
    Description: "API Prod stage endpoint"
    Value: !Sub "https://${APIGateWayRestApi}.execute-api.${AWS::Region}.amazonaws.com/${EnvironmentName}/"

  ExpenseWebsiteURL:
    Description: This is running server uri
    Value: !Join
      - ''
      - - 'http://'
        - !GetAtt
          - Ec2Instance
          - PublicDnsName
        - ':3000'
